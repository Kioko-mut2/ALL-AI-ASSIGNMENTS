Mastering the AI Toolkit – AI Tools Assignment

Group Members: [Insert Names]

Part 1: Theoretical Understanding
1. Short Answer Questions

Q1: TensorFlow vs PyTorch

TensorFlow: Uses static computation graphs (“define-then-run”), production-oriented, scalable deployment, TensorFlow Serving for models. Debugging is less intuitive.

PyTorch: Uses dynamic computation graphs (“define-by-run”), more flexible for experimentation and debugging, widely used in research.

When to choose:

Research and prototyping → PyTorch

Production deployment, mobile/edge devices → TensorFlow

Q2: Use cases for Jupyter Notebooks

Rapid experimentation: Quickly test ML/DL models and visualize results.

Collaboration and documentation: Combine code, explanations, and visual outputs in one interactive document that is shareable.

Q3: spaCy vs Basic Python String Operations

spaCy provides an efficient NLP pipeline: tokenization, POS tagging, named entity recognition (NER), and dependency parsing.

Advantages over string operations or regex:

Accurate recognition of multi-word entities.

Scalable to large datasets.

Less error-prone and more maintainable for complex NLP tasks.

2. Comparative Analysis
Feature	Scikit-learn	TensorFlow
Target Applications	Classical ML: regression, classification, clustering	Deep learning: CNNs, RNNs, transformers
Ease for Beginners	Very beginner-friendly, simple APIs	Moderate; requires understanding of tensors, layers
Community Support	Large, mature, extensive tutorials	Large and growing deep learning community
Part 2: Practical Implementation
Task 1: Iris Dataset – Decision Tree Classifier

Preprocessed dataset (handled missing values, encoded labels).

Model evaluation metrics:

Accuracy: [Insert screenshot here]

Confusion Matrix: [Insert screenshot here]

Notes: Decision tree chosen for interpretability; suitable for small datasets.

Task 2: MNIST – CNN Classifier

CNN architecture: two convolutional layers + max pooling + dense layers.

Data preprocessing: normalized images, reshaped to (28,28,1).

Training: 5 epochs with batch size 64.

Test Accuracy: >95% (insert screenshot of accuracy graph here)

Sample Predictions: Visualized 5 random test images with predicted vs true labels (insert screenshots here).

Task 3: Amazon Reviews – spaCy NER + Sentiment Analysis

NER extracted product names and brands from reviews.

Simple rule-based sentiment analysis using positive/negative lexicons.

Example output:

Review: "I love the Apple iPhone 12, the camera is amazing!"
Entities: [('Apple iPhone 12', 'PRODUCT')]
Sentiment: Positive


Screenshots of multiple outputs: [Insert here]

Part 3: Ethics & Optimization

MNIST Model Bias

Bias can occur due to differences in handwriting style (age, region, disability).

Mitigation: Data augmentation, evaluation across subgroups, TensorFlow Fairness Indicators.

Amazon Reviews Bias

Sentiment can be skewed by sarcasm, slang, or brand familiarity.

Mitigation: Combine spaCy rules with domain-specific lexicons, manually inspect outputs, balance datasets.

Optimization Notes

Normalized inputs to improve convergence.

Used batch processing in spaCy for efficiency.

Correct loss functions (SparseCategoricalCrossentropy) for classification to prevent training errors.

Screenshots Placeholders

Task 1: Accuracy + Confusion Matrix

Task 2: CNN Accuracy Graph + Sample Predictions

Task 3: NER Entities + Sentiment Analysis

Submission Instructions

Add screenshots in the placeholders.

Export this document as PDF.

Upload PDF to GitHub repository and Community/Peer Review platform.